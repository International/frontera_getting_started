## Tasks

1. *TODO* Using `SQLAlchemyBackend` try to add there `score` field to the
   table, put some code on the spider side calculating that score, and make it
   crawl records with higher score first. 

2. *TODO* Setup local hbase and kafka, try running it first
   http://distributed-frontera.readthedocs.org/en/latest/topics/quickstart.html

3. *TODO* if it’s working, than let’s make a new crawling strategy. Simpliest
   case: with your own scoring model and limited to crawl say 2000 urls.
